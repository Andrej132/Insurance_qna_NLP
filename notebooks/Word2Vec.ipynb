{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "be312e38-6a5f-4a8b-a5ca-c6e3690e2b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "import spacy\n",
    "from collections import Counter\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import pandas as pd\n",
    "import string\n",
    "sys.path.append(\"../data\")\n",
    "from test_data import original, easy, medium, hard\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39592ca3-f553-48c6-bdbe-dbc84df6701e",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ffac563b-1de6-4178-b4f3-ee75162cecaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_train = pd.read_csv('../data/insurance_qna_dataset.csv', delimiter='\\t')\n",
    "corpus_questions = corpus_train['Question'].drop_duplicates().tolist()\n",
    "\n",
    "changed_questions_test = easy + medium + hard\n",
    "corpus_test = pd.DataFrame({'Original': 3 * original, 'Changed': changed_questions_test})\n",
    "\n",
    "corpus_test_changed = corpus_test['Changed'].tolist()\n",
    "test_changed_list = [changed.strip().translate(str.maketrans(\"\",\"\",string.punctuation)) for changed in corpus_test_changed]\n",
    "original_test = corpus_test['Original'].tolist()\n",
    "original_questions = [original.strip().translate(str.maketrans(\"\",\"\",string.punctuation)) for original in original_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6efb8ca-9e07-4493-ac59-fc6e8eedd416",
   "metadata": {},
   "source": [
    "## 2. Tokenization, Lemmatization, Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bc48b058-4c79-4efb-8a8b-d88a1badeb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def preprocessing(corpus_list):\n",
    "    filtered_list = []\n",
    "    for sentence in corpus_list:\n",
    "        sentence = sentence.replace(\"?\",' ')\n",
    "        words = word_tokenize(sentence)\n",
    "        new_sentence = [w.lower().strip() for w in words if w.isalpha()]\n",
    "        filtered_list.append(new_sentence)\n",
    "    return filtered_list\n",
    "\n",
    "def lemmatize_tokenized(tokenized):\n",
    "    return [[lemmatizer.lemmatize(w) for w in ws] for ws in tokenized]\n",
    "\n",
    "def stem_tokenized(tokenized):\n",
    "    return [[stemmer.stem(w) for w in ws] for ws in tokenized]\n",
    "\n",
    "tokenized_questions = preprocessing(corpus_questions_list)\n",
    "lemmatized_questions = lemmatize_tokenized(tokenized_questions)\n",
    "stemmed_questions = stem_tokenized(tokenized_questions)\n",
    "\n",
    "tokenized_test_changed = preprocessing(test_changed_list)\n",
    "lemmatized_test_changed = lemmatize_tokenized(tokenized_test_changed)\n",
    "stemmed_test_changed = stem_tokenized(tokenized_test_changed)\n",
    "\n",
    "tokenized_original = preprocessing(original_questions)\n",
    "lemmatized_original = lemmatize_tokenized(tokenized_original)\n",
    "stemmed_original = stem_tokenized(tokenized_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5022979-7270-4f5f-96f2-a449e8907a0e",
   "metadata": {},
   "source": [
    "## 3. Embedding Functions (sum, avg, idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bbcd1109-87cd-44c7-82fc-f8ec89f971be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_Word2vec(all_vectors, model):\n",
    "    new_list = []\n",
    "    for sentence_vector in all_vectors:\n",
    "        if len(sentence_vector) == 0:\n",
    "            new_list.append(np.zeros(model.vector_size))\n",
    "            continue\n",
    "        vector = np.zeros(model.vector_size)\n",
    "        for word in sentence_vector:\n",
    "            if word in model.wv.index_to_key:\n",
    "                vector += model.wv[word]\n",
    "        new_list.append(vector)\n",
    "    return new_list\n",
    "\n",
    "def avg_Word2vec(all_vectors, model):\n",
    "    new_list = []\n",
    "    for sentence_vector in all_vectors:\n",
    "        sum_vector = np.zeros(model.vector_size)\n",
    "        word_fount = 0\n",
    "        for word in sentence_vector:\n",
    "            if word in model.wv.index_to_key:\n",
    "                sum_vector += model.wv[word]\n",
    "                word_fount += 1\n",
    "        if word_fount > 0:\n",
    "            new_list.append(sum_vector/word_fount)\n",
    "        else:\n",
    "            new_list.append(np.zeros(model.vector_size))\n",
    "    return new_list\n",
    "\n",
    "def IDF_Word2Vec(all_vectors, model, idf_dict):\n",
    "    new_list = []\n",
    "    for sentence_vector in all_vectors:\n",
    "        if len(sentence_vector) == 0:\n",
    "            new_list.append(np.zeros(model.vector_size))\n",
    "            continue\n",
    "        vector = np.zeros(model.vector_size)\n",
    "        total_weight = 0\n",
    "        for word in sentence_vector:\n",
    "            if word in model.wv.index_to_key and word in idf_dict:\n",
    "                vector += model.wv[word] * idf_dict[word]\n",
    "                total_weight += idf_dict[word]\n",
    "        if total_weight > 0:\n",
    "            new_list.append(vector / total_weight)\n",
    "        else:\n",
    "            new_list.append(np.zeros(model.vector_size))\n",
    "    return new_list\n",
    "\n",
    "def IDF_calculator(tokenized_documents):\n",
    "    number_of_documents = len(tokenized_documents)\n",
    "    document_freq = Counter()\n",
    "    for sentence in tokenized_documents:\n",
    "        unique_words = set(sentence)\n",
    "        for word in unique_words:\n",
    "            document_freq[word] += 1\n",
    "    idf_dict = {word: np.log((number_of_documents + 1) / (freq + 1)) + 1 for word, freq in document_freq.items()}\n",
    "    return idf_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7bc865-80d4-4fac-a6f0-06b860021bc9",
   "metadata": {},
   "source": [
    "## 4. KNN Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a9a0aef0-b7f9-409b-a637-5f55ee94e2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_knn(train_vectors, metric):\n",
    "    return NearestNeighbors(n_neighbors=100, algorithm='brute', metric=metric).fit(train_vectors)\n",
    "\n",
    "def k_nearest(model, matrix):\n",
    "    distance, indices = model.kneighbors(matrix.reshape(1,-1))\n",
    "    return distance, indices\n",
    "\n",
    "def ranking(model, test_data, corpus):\n",
    "    total_rank = 0\n",
    "    for elem in test_data:\n",
    "        changed_question, original = elem[0], elem[1]\n",
    "        _, indices = k_nearest(model, changed_question)\n",
    "        results = corpus[indices[0]]\n",
    "        for i, question in enumerate(results):\n",
    "            if original == question:\n",
    "                total_rank += i\n",
    "                break\n",
    "        if i == 99:\n",
    "            total_rank += 200\n",
    "    avg_rank = total_rank / len(test_data)\n",
    "    return avg_rank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6f8e18-20b9-4888-975b-2c47df868bd7",
   "metadata": {},
   "source": [
    "## 5. Word2Vec Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ac8456ea-427c-4b19-b410-976a639b7e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_cbow_orig = Word2Vec(tokenized_questions, vector_size=100, window=5, min_count=1, epochs=400, workers=7, sg=0,seed=123)\n",
    "w2v_cbow_lemm = Word2Vec(lemmatized_questions, vector_size=100, window=5, min_count=1, epochs=400, workers=7, sg=0,seed=123)\n",
    "w2v_cbow_stem = Word2Vec(stemmed_questions, vector_size=100, window=5, min_count=1, epochs=400, workers=7, sg=0,seed=123)\n",
    "\n",
    "w2v_skip_orig = Word2Vec(tokenized_questions, vector_size=100, window=5, min_count=1, epochs=400, workers=7, sg=1,seed=123)\n",
    "w2v_skip_lemm = Word2Vec(lemmatized_questions, vector_size=100, window=5, min_count=1, epochs=400, workers=7, sg=1,seed=123)\n",
    "w2v_skip_stem = Word2Vec(stemmed_questions, vector_size=100, window=5, min_count=1, epochs=400, workers=7, sg=1,seed=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afc4faf-6bfa-49b9-b7b3-b34ba6adb1d5",
   "metadata": {},
   "source": [
    "## 6. Embedding Preparation and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5601e1f0-12ce-46af-a8a1-0780b2852cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['cosine', 'manhattan', 'euclidean']\n",
    "embeddings = ['sum','avg','idf']\n",
    "results = []\n",
    "\n",
    "def sentence_embedding(emb_type, X, model, idf_dict=None):\n",
    "    if emb_type == 'sum':\n",
    "        return np.array(sum_Word2vec(X,model))\n",
    "    elif emb_type == 'avg':\n",
    "        return np.array(avg_Word2vec(X,model))\n",
    "    elif emb_type == 'idf':\n",
    "        return np.array(IDF_Word2Vec(X,model,idf_dict))\n",
    "    else:\n",
    "        raise ValueError(\"Unknown embedding type\")\n",
    "\n",
    "idf_orig = IDF_calculator(tokenized_questions)\n",
    "idf_lemm = IDF_calculator(lemmatized_questions)\n",
    "idf_stem = IDF_calculator(stemmed_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e9ff658c-1642-40d0-8eeb-e0ff9e615552",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cbow, model, train_X, test_X, orig_X, idf_dict in [\n",
    "    ('CBOW-original', w2v_cbow_orig, tokenized_questions, tokenized_test_changed, tokenized_original, idf_orig),\n",
    "    ('CBOW-lemma',    w2v_cbow_lemm,  lemmatized_questions, lemmatized_test_changed, lemmatized_original, idf_lemm),\n",
    "    ('CBOW-stem',     w2v_cbow_stem, stemmed_questions, stemmed_test_changed, stemmed_original, idf_stem)\n",
    "]:\n",
    "    for emb_type in embeddings:\n",
    "        if emb_type == 'idf':\n",
    "            train_vectors = sentence_embedding('idf', train_X, model, idf_dict)\n",
    "            test_vectors = sentence_embedding('idf', test_X, model, idf_dict)\n",
    "            orig_for_test = [' '.join(ws) for ws in orig_X]\n",
    "        else:\n",
    "            train_vectors = sentence_embedding(emb_type, train_X, model)\n",
    "            test_vectors = sentence_embedding(emb_type, test_X, model)\n",
    "            orig_for_test = [' '.join(ws) for ws in orig_X]\n",
    "        test_data = list(zip(test_vectors, orig_for_test))\n",
    "        for metric in metrics:\n",
    "            knn_model = train_knn(train_vectors, metric)\n",
    "            score = ranking(knn_model, test_data, np.array([' '.join(ws) for ws in train_X]))\n",
    "            results.append({\n",
    "                'Model': cbow,\n",
    "                'Embedding': emb_type,\n",
    "                'Distance': metric,\n",
    "                'Avg rank': score\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c4c5a98e-c562-4e1b-aa9f-393aa610daf8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for skipgram, model, train_X, test_X, orig_X, idf_dict in [\n",
    "    ('Skipgram-original', w2v_skip_orig,   tokenized_questions, tokenized_test_changed, tokenized_original, idf_orig),\n",
    "    ('Skipgram-lemma',    w2v_skip_lemm,    lemmatized_questions, lemmatized_test_changed, lemmatized_original, idf_lemm),\n",
    "    ('Skipgram-stem',     w2v_skip_stem,   stemmed_questions, stemmed_test_changed, stemmed_original, idf_stem)\n",
    "]:\n",
    "    for emb_type in embeddings:\n",
    "        if emb_type == 'idf':\n",
    "            train_vectors = sentence_embedding('idf', train_X, model, idf_dict)\n",
    "            test_vectors = sentence_embedding('idf', test_X, model, idf_dict)\n",
    "            orig_for_test = [' '.join(ws) for ws in orig_X]\n",
    "        else:\n",
    "            train_vectors = sentence_embedding(emb_type, train_X, model)\n",
    "            test_vectors = sentence_embedding(emb_type, test_X, model)\n",
    "            orig_for_test = [' '.join(ws) for ws in orig_X]\n",
    "        test_data = list(zip(test_vectors, orig_for_test))\n",
    "        for metric in metrics:\n",
    "            knn_model = train_knn(train_vectors, metric)\n",
    "            score = ranking(knn_model, test_data, np.array([' '.join(ws) for ws in train_X]))\n",
    "            results.append({\n",
    "                'Model': skipgram,\n",
    "                'Embedding': emb_type,\n",
    "                'Distance': metric,\n",
    "                'Avg rank': score\n",
    "            })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc0b79c-698b-4787-a5c3-7681b1f4beac",
   "metadata": {},
   "source": [
    "## 7. Results Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "db300ec5-a286-4643-89c8-00fb17fef3e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Embedding</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Avg rank</th>\n",
       "      <th>Processing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CBOW</td>\n",
       "      <td>avg</td>\n",
       "      <td>cosine</td>\n",
       "      <td>54.516667</td>\n",
       "      <td>lemma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CBOW</td>\n",
       "      <td>avg</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>58.166667</td>\n",
       "      <td>lemma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CBOW</td>\n",
       "      <td>avg</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>60.616667</td>\n",
       "      <td>lemma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>CBOW</td>\n",
       "      <td>idf</td>\n",
       "      <td>cosine</td>\n",
       "      <td>48.983333</td>\n",
       "      <td>lemma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>CBOW</td>\n",
       "      <td>idf</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>61.483333</td>\n",
       "      <td>lemma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CBOW</td>\n",
       "      <td>idf</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>61.383333</td>\n",
       "      <td>lemma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CBOW</td>\n",
       "      <td>sum</td>\n",
       "      <td>cosine</td>\n",
       "      <td>54.516667</td>\n",
       "      <td>lemma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CBOW</td>\n",
       "      <td>sum</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>57.183333</td>\n",
       "      <td>lemma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CBOW</td>\n",
       "      <td>sum</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>60.500000</td>\n",
       "      <td>lemma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CBOW</td>\n",
       "      <td>avg</td>\n",
       "      <td>cosine</td>\n",
       "      <td>53.833333</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CBOW</td>\n",
       "      <td>avg</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>62.033333</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CBOW</td>\n",
       "      <td>avg</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>61.983333</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CBOW</td>\n",
       "      <td>idf</td>\n",
       "      <td>cosine</td>\n",
       "      <td>52.333333</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CBOW</td>\n",
       "      <td>idf</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>64.750000</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CBOW</td>\n",
       "      <td>idf</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>63.983333</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CBOW</td>\n",
       "      <td>sum</td>\n",
       "      <td>cosine</td>\n",
       "      <td>53.833333</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CBOW</td>\n",
       "      <td>sum</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>57.883333</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CBOW</td>\n",
       "      <td>sum</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>57.516667</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>CBOW</td>\n",
       "      <td>avg</td>\n",
       "      <td>cosine</td>\n",
       "      <td>43.783333</td>\n",
       "      <td>stem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>CBOW</td>\n",
       "      <td>avg</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>52.933333</td>\n",
       "      <td>stem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>CBOW</td>\n",
       "      <td>avg</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>51.183333</td>\n",
       "      <td>stem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>CBOW</td>\n",
       "      <td>idf</td>\n",
       "      <td>cosine</td>\n",
       "      <td>42.700000</td>\n",
       "      <td>stem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>CBOW</td>\n",
       "      <td>idf</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>57.900000</td>\n",
       "      <td>stem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>CBOW</td>\n",
       "      <td>idf</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>59.483333</td>\n",
       "      <td>stem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>CBOW</td>\n",
       "      <td>sum</td>\n",
       "      <td>cosine</td>\n",
       "      <td>43.783333</td>\n",
       "      <td>stem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>CBOW</td>\n",
       "      <td>sum</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>49.766667</td>\n",
       "      <td>stem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>CBOW</td>\n",
       "      <td>sum</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>49.316667</td>\n",
       "      <td>stem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Skipgram</td>\n",
       "      <td>avg</td>\n",
       "      <td>cosine</td>\n",
       "      <td>41.616667</td>\n",
       "      <td>lemma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Skipgram</td>\n",
       "      <td>avg</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>51.866667</td>\n",
       "      <td>lemma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Skipgram</td>\n",
       "      <td>avg</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>51.550000</td>\n",
       "      <td>lemma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Skipgram</td>\n",
       "      <td>idf</td>\n",
       "      <td>cosine</td>\n",
       "      <td>39.166667</td>\n",
       "      <td>lemma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Skipgram</td>\n",
       "      <td>idf</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>58.133333</td>\n",
       "      <td>lemma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Skipgram</td>\n",
       "      <td>idf</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>63.050000</td>\n",
       "      <td>lemma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Skipgram</td>\n",
       "      <td>sum</td>\n",
       "      <td>cosine</td>\n",
       "      <td>41.616667</td>\n",
       "      <td>lemma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Skipgram</td>\n",
       "      <td>sum</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>34.883333</td>\n",
       "      <td>lemma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Skipgram</td>\n",
       "      <td>sum</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>35.100000</td>\n",
       "      <td>lemma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Skipgram</td>\n",
       "      <td>avg</td>\n",
       "      <td>cosine</td>\n",
       "      <td>41.683333</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Skipgram</td>\n",
       "      <td>avg</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>46.516667</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Skipgram</td>\n",
       "      <td>avg</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Skipgram</td>\n",
       "      <td>idf</td>\n",
       "      <td>cosine</td>\n",
       "      <td>46.250000</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Skipgram</td>\n",
       "      <td>idf</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>59.016667</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Skipgram</td>\n",
       "      <td>idf</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>60.583333</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Skipgram</td>\n",
       "      <td>sum</td>\n",
       "      <td>cosine</td>\n",
       "      <td>41.683333</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Skipgram</td>\n",
       "      <td>sum</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>39.550000</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Skipgram</td>\n",
       "      <td>sum</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>37.950000</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Skipgram</td>\n",
       "      <td>avg</td>\n",
       "      <td>cosine</td>\n",
       "      <td>32.766667</td>\n",
       "      <td>stem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Skipgram</td>\n",
       "      <td>avg</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>39.183333</td>\n",
       "      <td>stem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Skipgram</td>\n",
       "      <td>avg</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>39.583333</td>\n",
       "      <td>stem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Skipgram</td>\n",
       "      <td>idf</td>\n",
       "      <td>cosine</td>\n",
       "      <td>41.816667</td>\n",
       "      <td>stem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Skipgram</td>\n",
       "      <td>idf</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>52.533333</td>\n",
       "      <td>stem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Skipgram</td>\n",
       "      <td>idf</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>52.166667</td>\n",
       "      <td>stem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Skipgram</td>\n",
       "      <td>sum</td>\n",
       "      <td>cosine</td>\n",
       "      <td>32.766667</td>\n",
       "      <td>stem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Skipgram</td>\n",
       "      <td>sum</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>32.166667</td>\n",
       "      <td>stem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Skipgram</td>\n",
       "      <td>sum</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>32.250000</td>\n",
       "      <td>stem</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Model Embedding   Distance   Avg rank Processing\n",
       "12      CBOW       avg     cosine  54.516667      lemma\n",
       "14      CBOW       avg  euclidean  58.166667      lemma\n",
       "13      CBOW       avg  manhattan  60.616667      lemma\n",
       "15      CBOW       idf     cosine  48.983333      lemma\n",
       "17      CBOW       idf  euclidean  61.483333      lemma\n",
       "16      CBOW       idf  manhattan  61.383333      lemma\n",
       "9       CBOW       sum     cosine  54.516667      lemma\n",
       "11      CBOW       sum  euclidean  57.183333      lemma\n",
       "10      CBOW       sum  manhattan  60.500000      lemma\n",
       "3       CBOW       avg     cosine  53.833333   original\n",
       "5       CBOW       avg  euclidean  62.033333   original\n",
       "4       CBOW       avg  manhattan  61.983333   original\n",
       "6       CBOW       idf     cosine  52.333333   original\n",
       "8       CBOW       idf  euclidean  64.750000   original\n",
       "7       CBOW       idf  manhattan  63.983333   original\n",
       "0       CBOW       sum     cosine  53.833333   original\n",
       "2       CBOW       sum  euclidean  57.883333   original\n",
       "1       CBOW       sum  manhattan  57.516667   original\n",
       "21      CBOW       avg     cosine  43.783333       stem\n",
       "23      CBOW       avg  euclidean  52.933333       stem\n",
       "22      CBOW       avg  manhattan  51.183333       stem\n",
       "24      CBOW       idf     cosine  42.700000       stem\n",
       "26      CBOW       idf  euclidean  57.900000       stem\n",
       "25      CBOW       idf  manhattan  59.483333       stem\n",
       "18      CBOW       sum     cosine  43.783333       stem\n",
       "20      CBOW       sum  euclidean  49.766667       stem\n",
       "19      CBOW       sum  manhattan  49.316667       stem\n",
       "39  Skipgram       avg     cosine  41.616667      lemma\n",
       "41  Skipgram       avg  euclidean  51.866667      lemma\n",
       "40  Skipgram       avg  manhattan  51.550000      lemma\n",
       "42  Skipgram       idf     cosine  39.166667      lemma\n",
       "44  Skipgram       idf  euclidean  58.133333      lemma\n",
       "43  Skipgram       idf  manhattan  63.050000      lemma\n",
       "36  Skipgram       sum     cosine  41.616667      lemma\n",
       "38  Skipgram       sum  euclidean  34.883333      lemma\n",
       "37  Skipgram       sum  manhattan  35.100000      lemma\n",
       "30  Skipgram       avg     cosine  41.683333   original\n",
       "32  Skipgram       avg  euclidean  46.516667   original\n",
       "31  Skipgram       avg  manhattan  49.000000   original\n",
       "33  Skipgram       idf     cosine  46.250000   original\n",
       "35  Skipgram       idf  euclidean  59.016667   original\n",
       "34  Skipgram       idf  manhattan  60.583333   original\n",
       "27  Skipgram       sum     cosine  41.683333   original\n",
       "29  Skipgram       sum  euclidean  39.550000   original\n",
       "28  Skipgram       sum  manhattan  37.950000   original\n",
       "48  Skipgram       avg     cosine  32.766667       stem\n",
       "50  Skipgram       avg  euclidean  39.183333       stem\n",
       "49  Skipgram       avg  manhattan  39.583333       stem\n",
       "51  Skipgram       idf     cosine  41.816667       stem\n",
       "53  Skipgram       idf  euclidean  52.533333       stem\n",
       "52  Skipgram       idf  manhattan  52.166667       stem\n",
       "45  Skipgram       sum     cosine  32.766667       stem\n",
       "47  Skipgram       sum  euclidean  32.166667       stem\n",
       "46  Skipgram       sum  manhattan  32.250000       stem"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = pd.DataFrame(results)\n",
    "df_results[['Model', 'Processing']] = df_results['Model'].str.split('-', n=1, expand=True)\n",
    "df_results = df_results.sort_values(['Model', 'Processing', 'Embedding', 'Distance'])\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7ed6ca98-6ab4-4829-b324-5bc0c88b2580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Distance</th>\n",
       "      <th>cosine</th>\n",
       "      <th>euclidean</th>\n",
       "      <th>manhattan</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th>Processing</th>\n",
       "      <th>Embedding</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">CBOW</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">lemma</th>\n",
       "      <th>avg</th>\n",
       "      <td>54.516667</td>\n",
       "      <td>58.166667</td>\n",
       "      <td>60.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idf</th>\n",
       "      <td>48.983333</td>\n",
       "      <td>61.483333</td>\n",
       "      <td>61.383333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sum</th>\n",
       "      <td>54.516667</td>\n",
       "      <td>57.183333</td>\n",
       "      <td>60.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">original</th>\n",
       "      <th>avg</th>\n",
       "      <td>53.833333</td>\n",
       "      <td>62.033333</td>\n",
       "      <td>61.983333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idf</th>\n",
       "      <td>52.333333</td>\n",
       "      <td>64.750000</td>\n",
       "      <td>63.983333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sum</th>\n",
       "      <td>53.833333</td>\n",
       "      <td>57.883333</td>\n",
       "      <td>57.516667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">stem</th>\n",
       "      <th>avg</th>\n",
       "      <td>43.783333</td>\n",
       "      <td>52.933333</td>\n",
       "      <td>51.183333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idf</th>\n",
       "      <td>42.700000</td>\n",
       "      <td>57.900000</td>\n",
       "      <td>59.483333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sum</th>\n",
       "      <td>43.783333</td>\n",
       "      <td>49.766667</td>\n",
       "      <td>49.316667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">Skipgram</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">lemma</th>\n",
       "      <th>avg</th>\n",
       "      <td>41.616667</td>\n",
       "      <td>51.866667</td>\n",
       "      <td>51.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idf</th>\n",
       "      <td>39.166667</td>\n",
       "      <td>58.133333</td>\n",
       "      <td>63.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sum</th>\n",
       "      <td>41.616667</td>\n",
       "      <td>34.883333</td>\n",
       "      <td>35.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">original</th>\n",
       "      <th>avg</th>\n",
       "      <td>41.683333</td>\n",
       "      <td>46.516667</td>\n",
       "      <td>49.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idf</th>\n",
       "      <td>46.250000</td>\n",
       "      <td>59.016667</td>\n",
       "      <td>60.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sum</th>\n",
       "      <td>41.683333</td>\n",
       "      <td>39.550000</td>\n",
       "      <td>37.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">stem</th>\n",
       "      <th>avg</th>\n",
       "      <td>32.766667</td>\n",
       "      <td>39.183333</td>\n",
       "      <td>39.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idf</th>\n",
       "      <td>41.816667</td>\n",
       "      <td>52.533333</td>\n",
       "      <td>52.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sum</th>\n",
       "      <td>32.766667</td>\n",
       "      <td>32.166667</td>\n",
       "      <td>32.250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Distance                          cosine  euclidean  manhattan\n",
       "Model    Processing Embedding                                 \n",
       "CBOW     lemma      avg        54.516667  58.166667  60.616667\n",
       "                    idf        48.983333  61.483333  61.383333\n",
       "                    sum        54.516667  57.183333  60.500000\n",
       "         original   avg        53.833333  62.033333  61.983333\n",
       "                    idf        52.333333  64.750000  63.983333\n",
       "                    sum        53.833333  57.883333  57.516667\n",
       "         stem       avg        43.783333  52.933333  51.183333\n",
       "                    idf        42.700000  57.900000  59.483333\n",
       "                    sum        43.783333  49.766667  49.316667\n",
       "Skipgram lemma      avg        41.616667  51.866667  51.550000\n",
       "                    idf        39.166667  58.133333  63.050000\n",
       "                    sum        41.616667  34.883333  35.100000\n",
       "         original   avg        41.683333  46.516667  49.000000\n",
       "                    idf        46.250000  59.016667  60.583333\n",
       "                    sum        41.683333  39.550000  37.950000\n",
       "         stem       avg        32.766667  39.183333  39.583333\n",
       "                    idf        41.816667  52.533333  52.166667\n",
       "                    sum        32.766667  32.166667  32.250000"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivot = df_results.pivot_table(\n",
    "    index=['Model', 'Processing', 'Embedding'],\n",
    "    columns='Distance',\n",
    "    values='Avg rank'\n",
    ")\n",
    "pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dba4d79-b6fe-451c-b09b-b2b8240965ce",
   "metadata": {},
   "source": [
    "## 8. Best Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e1149753-2c47-4b2d-9968-60d2f23cd1fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best result:\n",
      "Model          Skipgram\n",
      "Embedding           sum\n",
      "Distance      euclidean\n",
      "Avg rank      32.166667\n",
      "Processing         stem\n",
      "Name: 47, dtype: object\n"
     ]
    }
   ],
   "source": [
    "best_row = df_results.loc[df_results['Avg rank'].idxmin()]\n",
    "print(\"\\nBest result:\")\n",
    "print(best_row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
